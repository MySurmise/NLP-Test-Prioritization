{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings:\n",
    "\n",
    "cluster_labels_steps = cluster_labels_steps_kmeans\n",
    "cluster_labels_results = cluster_labels_results_kmeans\n",
    "num_clusters = kmeans_results.n_clusters\n",
    "\n",
    "#-------\n",
    "\n",
    "test_specs[\"stepsToReproduceClusters\"] = [[] for _ in range(len(test_specs))]\n",
    "test_specs[\"stepsToReproduceVector\"] = [[0] * num_clusters for _ in range(len(test_specs))]\n",
    "\n",
    "stepcounter = 0\n",
    "testcounter = 0\n",
    "for manualTest in test_specs[\"stepsToReproduceEmbeddings\"]:\n",
    "    for stepEmbedding in manualTest:\n",
    "        if not isinstance(test_specs[\"stepsToReproduceClusters\"].iloc[testcounter], list):\n",
    "            test_specs[\"stepsToReproduceClusters\"].iloc[testcounter] = []\n",
    "        test_specs[\"stepsToReproduceClusters\"].iloc[testcounter].append(\n",
    "            cluster_labels_steps[stepcounter]\n",
    "        )\n",
    "        test_specs[\"stepsToReproduceVector\"].iloc[testcounter][\n",
    "            cluster_labels_steps[stepcounter]\n",
    "        ] += 1\n",
    "        stepcounter += 1\n",
    "    testcounter += 1\n",
    "\n",
    "test_specs[\"expectedResultsClusters\"] = [[] for _ in range(len(test_specs))]\n",
    "test_specs[\"expectedResultsVector\"] = [[0] * num_clusters for _ in range(len(test_specs))]\n",
    "\n",
    "\n",
    "resultcounter = 0\n",
    "testcounter = 0\n",
    "for manualTest in test_specs[\"expectedResultsEmbeddings\"]:\n",
    "    for stepEmbedding in manualTest:\n",
    "        if not isinstance(test_specs[\"expectedResultsClusters\"].iloc[testcounter], list):\n",
    "            test_specs[\"expectedResultsClusters\"].iloc[testcounter] = []\n",
    "        test_specs[\"expectedResultsClusters\"].iloc[testcounter].append(\n",
    "            cluster_labels_results[resultcounter]\n",
    "        )\n",
    "        test_specs[\"expectedResultsVector\"].iloc[testcounter][\n",
    "            cluster_labels_results[resultcounter]\n",
    "        ] += 1\n",
    "        resultcounter += 1\n",
    "    testcounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline, logging\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "import argparse\n",
    "\n",
    "model_name_or_path = \"TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ\"\n",
    "model_basename = \"wizardlm-13b-v1.1-superhot-8k-GPTQ-4bit-128g.no-act.order\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(\n",
    "    model_name_or_path,\n",
    "    model_basename=model_basename,\n",
    "    use_safetensors=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    use_triton=use_triton,\n",
    "    quantize_config=None,\n",
    ")\n",
    "\n",
    "model.seqlen = 8192\n",
    "\n",
    "# Note: check the prompt template is correct for this model.\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template = f\"\"\"USER: {prompt}\n",
    "ASSISTANT:\"\"\"\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "# Prevent printing spurious transformers error when using pipeline with AutoGPTQ\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15,\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, logging\n",
    "\n",
    "logging.set_verbosity(logging.DEBUG)\n",
    "\n",
    "# Initialize a text-generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "\n",
    "# Generate text based on a prompt\n",
    "prompt = \"In a distant future, humanity has\"\n",
    "generated_text = generator(\n",
    "    prompt, max_length=50, num_return_sequences=5, temperature=0.7\n",
    ")\n",
    "\n",
    "for i, text in enumerate(generated_text):\n",
    "    print(f\"Generated text {i+1}:\")\n",
    "    print(text[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9891/2074761894.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embedding = torch.mean(torch.tensor(embedding), dim=1).numpy()\n",
      "/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_9891/2074761894.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embedding = torch.mean(torch.tensor(embedding), dim=1).numpy()\n",
      "/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_9891/2074761894.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embedding = torch.mean(torch.tensor(embedding), dim=1).numpy()\n",
      "/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_9891/2074761894.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embedding = torch.mean(torch.tensor(embedding), dim=1).numpy()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32m/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m test_info[\u001b[39m\"\u001b[39m\u001b[39mTestName_Embedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_info[\u001b[39m\"\u001b[39m\u001b[39mTest Name\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(get_bert_embedding)\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m test_specs[\u001b[39m\"\u001b[39m\u001b[39mexpectedResultEmbeddings\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_specs[\u001b[39m\"\u001b[39m\u001b[39mexpectedResult\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     get_bert_embedding_for_list\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m )\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m test_specs[\u001b[39m\"\u001b[39m\u001b[39mstepsToReproduceEmbeddings\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_specs[\u001b[39m\"\u001b[39;49m\u001b[39mstepsToReproduce\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     get_bert_embedding_for_list\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n",
      "\u001b[1;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n",
      "\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n",
      "\u001b[1;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n",
      "\u001b[1;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n",
      "\u001b[1;32m   4636\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   4751\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n",
      "\u001b[1;32m   4752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   4753\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n",
      "\u001b[1;32m   4754\u001b[0m         \u001b[39mself\u001b[39;49m,\n",
      "\u001b[1;32m   4755\u001b[0m         func,\n",
      "\u001b[1;32m   4756\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n",
      "\u001b[1;32m   4757\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n",
      "\u001b[1;32m   4758\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n",
      "\u001b[1;32m   4759\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n",
      "\u001b[0;32m-> 4760\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n",
      "\u001b[1;32m   1206\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n",
      "\u001b[0;32m-> 1207\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m   1281\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n",
      "\u001b[1;32m   1282\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n",
      "\u001b[1;32m   1283\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n",
      "\u001b[1;32m   1284\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n",
      "\u001b[1;32m   1285\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n",
      "\u001b[1;32m   1286\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 1287\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n",
      "\u001b[1;32m   1288\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n",
      "\u001b[1;32m   1289\u001b[0m )\n",
      "\u001b[1;32m   1291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n",
      "\u001b[1;32m   1292\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n",
      "\u001b[1;32m   1293\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n",
      "\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n",
      "\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n",
      "\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n",
      "\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n",
      "\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n",
      "\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n",
      "\u001b[1;32m   1818\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\n",
      "\u001b[1;32m/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bert_embedding_for_list\u001b[39m(list_of_text):\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [get_bert_embedding(text) \u001b[39mfor\u001b[39;49;00m text \u001b[39min\u001b[39;49;00m list_of_text]\n",
      "\n",
      "\u001b[1;32m/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bert_embedding_for_list\u001b[39m(list_of_text):\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [get_bert_embedding(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n",
      "\n",
      "\u001b[1;32m/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bert_embedding\u001b[39m(text):\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# Get embeddings using the pipeline\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     text \u001b[39m=\u001b[39m ensure_string_format(text)\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     embedding \u001b[39m=\u001b[39m bert_pipeline(\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         text, return_tensors\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     )\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     sentence_embedding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mtensor(embedding), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# print(embedding[0])\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/home/fedrive/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/notebooks/import.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# Average the token embeddings\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/feature_extraction.py:107\u001b[0m, in \u001b[0;36mFeatureExtractionPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[1;32m     98\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m     99\u001b[0m \u001b[39m    Extract the features of the input(s).\u001b[39;00m\n",
      "\u001b[1;32m    100\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    105\u001b[0m \u001b[39m        A nested list of `float`: The features computed by the model.\u001b[39;00m\n",
      "\u001b[1;32m    106\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n",
      "\u001b[1;32m   1133\u001b[0m         \u001b[39miter\u001b[39m(\n",
      "\u001b[1;32m   1134\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1137\u001b[0m         )\n",
      "\u001b[1;32m   1138\u001b[0m     )\n",
      "\u001b[1;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n",
      "\u001b[1;32m   1145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n",
      "\u001b[1;32m   1146\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n",
      "\u001b[0;32m-> 1147\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n",
      "\u001b[1;32m   1148\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n",
      "\u001b[1;32m   1149\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1045\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n",
      "\u001b[1;32m   1043\u001b[0m inference_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_inference_context()\n",
      "\u001b[1;32m   1044\u001b[0m \u001b[39mwith\u001b[39;00m inference_context():\n",
      "\u001b[0;32m-> 1045\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "\u001b[1;32m   1046\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n",
      "\u001b[1;32m   1047\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\n",
      "File \u001b[0;32m~/Studium/Semester_5/Seminar/NLP-Test-Prioritization/python_src/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:949\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n",
      "\u001b[1;32m    947\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mdict\u001b[39m):\n",
      "\u001b[1;32m    948\u001b[0m     \u001b[39mreturn\u001b[39;00m {name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[39mfor\u001b[39;00m name, tensor \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[0;32m--> 949\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, UserDict):\n",
      "\u001b[1;32m    950\u001b[0m     \u001b[39mreturn\u001b[39;00m UserDict({name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[39mfor\u001b[39;00m name, tensor \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()})\n",
      "\u001b[1;32m    951\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m):\n",
      "\n",
      "File \u001b[0;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Create a pipeline for the BERT model\n",
    "bert_pipeline = pipeline(\n",
    "    \"feature-extraction\",\n",
    "    model=\"bert-base-uncased\",\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")\n",
    "\n",
    "\n",
    "def ensure_string_format(data):\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    elif isinstance(data, list):\n",
    "        return [\n",
    "            str(item) for item in data\n",
    "        ]  # Convert each item to string if not already\n",
    "    else:\n",
    "        print(\"WARNING, WRONG DATA\")\n",
    "        print(data)\n",
    "        return str(data)  # Convert other types to string\n",
    "\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    # Get embeddings using the pipeline\n",
    "    text = ensure_string_format(text)\n",
    "    embedding = bert_pipeline(\n",
    "        text, return_tensors=True, padding=True, truncation=True, max_length=128\n",
    "    )\n",
    "    sentence_embedding = torch.mean(torch.tensor(embedding), dim=1).numpy()\n",
    "    # print(embedding[0])\n",
    "    # Average the token embeddings\n",
    "    return sentence_embedding\n",
    "\n",
    "\n",
    "# TODO: Try to use parallel embedding feature from pipelines by giving it the entire list at once\n",
    "def get_bert_embedding_for_list(list_of_text):\n",
    "    return [get_bert_embedding(text) for text in list_of_text]\n",
    "\n",
    "\n",
    "# Embeddings for each line\n",
    "test_info[\"Category_Embedding\"] = test_info[\"Category\"].apply(get_bert_embedding)\n",
    "test_info[\"TestName_Embedding\"] = test_info[\"Test Name\"].apply(get_bert_embedding)\n",
    "test_specs[\"expectedResultEmbeddings\"] = test_specs[\"expectedResult\"].apply(\n",
    "    get_bert_embedding_for_list\n",
    ")\n",
    "test_specs[\"stepsToReproduceEmbeddings\"] = test_specs[\"stepsToReproduce\"].apply(\n",
    "    get_bert_embedding_for_list\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
